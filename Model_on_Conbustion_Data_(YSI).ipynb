{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow 2.8.0\n",
      "nfp 0+unknown\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import nfp\n",
    "\n",
    "print(f\"tensorflow {tf.__version__}\")\n",
    "print(f\"nfp {nfp.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>CAS</th>\n",
       "      <th>Type</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>YSI</th>\n",
       "      <th>YSI_err</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>isocetane</td>\n",
       "      <td>4390-04-9</td>\n",
       "      <td>alkanes</td>\n",
       "      <td>CC(CC(C)(C)C)CC(C)(C)CC(C)(C)C</td>\n",
       "      <td>128.0</td>\n",
       "      <td>6.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1,4-cyclohexanedimethanol divinyl ether</td>\n",
       "      <td>17351-75-6</td>\n",
       "      <td>oxygenates</td>\n",
       "      <td>C=COCC1CCC(COC=C)CC1</td>\n",
       "      <td>130.5</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gamma-Undecalactone</td>\n",
       "      <td>104-67-6</td>\n",
       "      <td>esters</td>\n",
       "      <td>CCCCCCCC1CCC(=O)O1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ethyl decanoate</td>\n",
       "      <td>110-38-3</td>\n",
       "      <td>esters</td>\n",
       "      <td>CCCCCCCCCC(=O)OCC</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>butyl decanoate</td>\n",
       "      <td>30673-36-0</td>\n",
       "      <td>esters</td>\n",
       "      <td>CCCCCCCCCC(=O)OCCCC</td>\n",
       "      <td>82.6</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Species         CAS        Type  \\\n",
       "0                                isocetane   4390-04-9     alkanes   \n",
       "1  1,4-cyclohexanedimethanol divinyl ether  17351-75-6  oxygenates   \n",
       "2                      gamma-Undecalactone    104-67-6      esters   \n",
       "3                          ethyl decanoate    110-38-3      esters   \n",
       "4                          butyl decanoate  30673-36-0      esters   \n",
       "\n",
       "                           SMILES    YSI  YSI_err  \n",
       "0  CC(CC(C)(C)C)CC(C)(C)CC(C)(C)C  128.0      6.4  \n",
       "1            C=COCC1CCC(COC=C)CC1  130.5      6.5  \n",
       "2              CCCCCCCC1CCC(=O)O1   58.2      2.9  \n",
       "3               CCCCCCCCCC(=O)OCC   58.0      2.9  \n",
       "4             CCCCCCCCCC(=O)OCCCC   82.6      4.1  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the input data, here YSI (10.1016/j.combustflame.2017.12.005)\n",
    "# ysi.csv available from https://github.com/pstjohn/YSIs_for_prediction/\n",
    "ysi = pd.read_csv('ysi.csv')\n",
    "ysi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 50, 50)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets\n",
    "valid, test, train = np.split(ysi.SMILES.sample(frac=1., random_state=1), [50, 100])\n",
    "len(train), len(valid), len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define how to featurize the input molecules\n",
    "from nfp.preprocessing.mol_preprocessor import SmilesPreprocessor\n",
    "from nfp.preprocessing.features import get_ring_size\n",
    "\n",
    "\n",
    "def atom_featurizer(atom):\n",
    "    \"\"\" Return an string representing the atom type\n",
    "    \"\"\"\n",
    "\n",
    "    return str((\n",
    "        atom.GetSymbol(),\n",
    "        atom.GetIsAromatic(),\n",
    "        get_ring_size(atom, max_size=6),\n",
    "        atom.GetDegree(),\n",
    "        atom.GetTotalNumHs(includeNeighbors=True)\n",
    "    ))\n",
    "\n",
    "\n",
    "def bond_featurizer(bond, flipped=False):\n",
    "    \"\"\" Get a similar classification of the bond type.\n",
    "    Flipped indicates which 'direction' the bond edge is pointing. \"\"\"\n",
    "    \n",
    "    if not flipped:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetBeginAtom().GetSymbol(),\n",
    "                    bond.GetEndAtom().GetSymbol())))\n",
    "    else:\n",
    "        atoms = \"{}-{}\".format(\n",
    "            *tuple((bond.GetEndAtom().GetSymbol(),\n",
    "                    bond.GetBeginAtom().GetSymbol())))\n",
    "    \n",
    "    btype = str(bond.GetBondType())\n",
    "    ring = 'R{}'.format(get_ring_size(bond, max_size=6)) if bond.IsInRing() else ''\n",
    "    \n",
    "    return \" \".join([atoms, btype, ring]).strip()\n",
    "\n",
    "\n",
    "preprocessor = SmilesPreprocessor(atom_features=atom_featurizer, bond_features=bond_featurizer,\n",
    "                                  explicit_hs=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before pre-allocating\n",
      "{'unk': 1}\n",
      "\n",
      "after pre-allocating\n",
      "{'unk': 1, \"('C', False, 0, 1, 2)\": 2, \"('C', False, 0, 2, 1)\": 3, \"('C', False, 0, 2, 2)\": 4, \"('C', False, 0, 3, 1)\": 5, \"('C', False, 0, 1, 3)\": 6, \"('O', False, 0, 2, 0)\": 7, \"('C', False, 0, 3, 0)\": 8, \"('O', False, 0, 1, 0)\": 9, \"('C', False, 'max', 3, 1)\": 10, \"('C', False, 'max', 2, 2)\": 11, \"('O', False, 0, 1, 1)\": 12, \"('C', False, 0, 2, 0)\": 13, \"('N', False, 0, 1, 0)\": 14, \"('C', True, 'max', 2, 1)\": 15, \"('C', True, 'max', 3, 0)\": 16, \"('N', True, 'max', 2, 0)\": 17, \"('C', True, 5, 3, 0)\": 18, \"('C', False, 5, 2, 2)\": 19, \"('N', False, 5, 2, 1)\": 20, \"('C', False, 0, 4, 0)\": 21, \"('C', True, 5, 2, 1)\": 22, \"('O', True, 5, 2, 0)\": 23, \"('N', False, 0, 1, 1)\": 24, \"('C', False, 5, 2, 1)\": 25, \"('C', False, 5, 3, 1)\": 26, \"('N', True, 5, 2, 1)\": 27, \"('N', False, 0, 2, 0)\": 28, \"('N', False, 0, 2, 1)\": 29, \"('C', False, 'max', 2, 1)\": 30, \"('O', False, 5, 2, 0)\": 31, \"('N', False, 0, 1, 2)\": 32, \"('C', False, 4, 3, 1)\": 33, \"('C', False, 4, 2, 2)\": 34, \"('O', False, 4, 2, 0)\": 35, \"('C', False, 0, 1, 1)\": 36, \"('C', False, 5, 3, 0)\": 37, \"('C', False, 5, 4, 0)\": 38, \"('N', False, 'max', 2, 1)\": 39, \"('N', True, 5, 3, 0)\": 40, \"('N', False, 0, 3, 0)\": 41, \"('N', False, 'max', 2, 0)\": 42, \"('N', False, 5, 3, 0)\": 43, \"('C', False, 'max', 3, 0)\": 44, \"('N', False, 'max', 3, 0)\": 45, \"('C', False, 3, 3, 1)\": 46, \"('C', False, 3, 4, 0)\": 47, \"('C', False, 'max', 4, 0)\": 48, \"('N', False, 4, 2, 1)\": 49, \"('C', False, 4, 4, 0)\": 50, \"('O', False, 'max', 2, 0)\": 51, \"('C', False, 3, 2, 2)\": 52, \"('Br', False, 0, 1, 0)\": 53, \"('Cl', False, 0, 1, 0)\": 54, \"('F', False, 0, 1, 0)\": 55}\n"
     ]
    }
   ],
   "source": [
    "# Initially, the preprocessor has no data on atom types, so we have to loop over the \n",
    "# training set once to pre-allocate these mappings\n",
    "print(\"before pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)\n",
    "\n",
    "for smiles in train:\n",
    "    preprocessor(smiles, train=True)\n",
    "    \n",
    "print()\n",
    "print(\"after pre-allocating\")\n",
    "print(preprocessor.atom_tokenizer._data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6,  4, 12], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Main input types for a SMILES-based prediction\n",
    "smiles = 'CCO'\n",
    "\n",
    "# Atom types, as integer classes\n",
    "preprocessor(smiles, train=True)['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 4, 5], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bond types, as integer classes\n",
    "preprocessor(smiles, train=True)['bond']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 2],\n",
       "       [2, 1]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A connectivity array, where row i indicates bond i connects atom j to atom k\n",
    "preprocessor(smiles, train=True)['connectivity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tf.data pipeline. There's a lot of specifying data types and\n",
    "# expected shapes for tensorflow to pre-allocate the necessary arrays. But \n",
    "# essentially, this is responsible for calling the input constructor, batching \n",
    "# together multiple molecules, and padding the resulting molecules so that all\n",
    "# molecules in the same batch have the same number of atoms (we pad with zeros,\n",
    "# hence why the atom and bond types above start with 1 as the unknown class)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(train)].iterrows()),\n",
    "    output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\\\n",
    "    .cache().shuffle(buffer_size=200)\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: ((preprocessor(row.SMILES, train=False), row.YSI)\n",
    "             for i, row in ysi[ysi.SMILES.isin(valid)].iterrows()),\n",
    "    output_signature=(preprocessor.output_signature, tf.TensorSpec((), dtype=tf.float32)))\\\n",
    "    .cache()\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-07 19:37:08.950818: W tensorflow/core/kernels/data/cache_dataset_ops.cc:768] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 6,  4, 13, ...,  0,  0,  0],\n",
       "       [ 6,  4,  4, ...,  0,  0,  0],\n",
       "       [ 6, 16, 16, ...,  0,  0,  0],\n",
       "       ...,\n",
       "       [ 2,  3,  7, ...,  0,  0,  0],\n",
       "       [25, 25, 31, ...,  0,  0,  0],\n",
       "       [30, 30, 11, ...,  0,  0,  0]], dtype=int32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs, outputs = next(train_dataset.as_numpy_iterator())\n",
    "inputs['atom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the keras model\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Input layers\n",
    "atom = layers.Input(shape=[None], dtype=tf.int64, name='atom')\n",
    "bond = layers.Input(shape=[None], dtype=tf.int64, name='bond')\n",
    "connectivity = layers.Input(shape=[None, 2], dtype=tf.int64, name='connectivity')\n",
    "\n",
    "num_features = 8  # Controls the size of the model\n",
    "\n",
    "# Convert from a single integer defining the atom state to a vector\n",
    "# of weights associated with that class\n",
    "atom_state = layers.Embedding(preprocessor.atom_classes, num_features,\n",
    "                              name='atom_embedding', mask_zero=True)(atom)\n",
    "\n",
    "# Ditto with the bond state\n",
    "bond_state = layers.Embedding(preprocessor.bond_classes, num_features,\n",
    "                              name='bond_embedding', mask_zero=True)(bond)\n",
    "\n",
    "# Here we use our first nfp layer. This is an attention layer that looks at\n",
    "# the atom and bond states and reduces them to a single, graph-level vector. \n",
    "# mum_heads * units has to be the same dimension as the atom / bond dimension\n",
    "global_state = nfp.GlobalUpdate(units=8, num_heads=1)([atom_state, bond_state, connectivity])\n",
    "\n",
    "for _ in range(3):  # Do the message passing\n",
    "    new_bond_state = nfp.EdgeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    bond_state = layers.Add()([bond_state, new_bond_state])\n",
    "    \n",
    "    new_atom_state = nfp.NodeUpdate()([atom_state, bond_state, connectivity, global_state])\n",
    "    atom_state = layers.Add()([atom_state, new_atom_state])\n",
    "    \n",
    "    new_global_state = nfp.GlobalUpdate(units=8, num_heads=1)(\n",
    "        [atom_state, bond_state, connectivity, global_state]) \n",
    "    global_state = layers.Add()([global_state, new_global_state])\n",
    "\n",
    "    \n",
    "# Since the final prediction is a single, molecule-level property (YSI), we \n",
    "# reduce the last global state to a single prediction.\n",
    "ysi_prediction = layers.Dense(1)(global_state)\n",
    "\n",
    "# Construct the tf.keras model\n",
    "model = tf.keras.Model([atom, bond, connectivity], [ysi_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "9/9 [==============================] - 16s 471ms/step - loss: 145.7803 - val_loss: 132.1886\n",
      "Epoch 2/25\n",
      "9/9 [==============================] - 0s 34ms/step - loss: 142.8636 - val_loss: 125.1585\n",
      "Epoch 3/25\n",
      "9/9 [==============================] - 0s 41ms/step - loss: 130.8008 - val_loss: 104.9459\n",
      "Epoch 4/25\n",
      "9/9 [==============================] - 0s 32ms/step - loss: 118.7174 - val_loss: 99.8784\n",
      "Epoch 5/25\n",
      "9/9 [==============================] - 0s 28ms/step - loss: 110.6385 - val_loss: 96.5609\n",
      "Epoch 6/25\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 107.1249 - val_loss: 92.6281\n",
      "Epoch 7/25\n",
      "9/9 [==============================] - 0s 39ms/step - loss: 101.7515 - val_loss: 82.9378\n",
      "Epoch 8/25\n",
      "9/9 [==============================] - 0s 33ms/step - loss: 89.9552 - val_loss: 64.1952\n",
      "Epoch 9/25\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 77.1562 - val_loss: 58.7141\n",
      "Epoch 10/25\n",
      "9/9 [==============================] - 0s 30ms/step - loss: 68.2843 - val_loss: 55.8786\n",
      "Epoch 11/25\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 64.0670 - val_loss: 51.2922\n",
      "Epoch 12/25\n",
      "9/9 [==============================] - 1s 68ms/step - loss: 65.0574 - val_loss: 54.3573\n",
      "Epoch 13/25\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 60.3207 - val_loss: 52.7504\n",
      "Epoch 14/25\n",
      "9/9 [==============================] - 1s 61ms/step - loss: 58.6072 - val_loss: 49.4788\n",
      "Epoch 15/25\n",
      "9/9 [==============================] - 1s 69ms/step - loss: 58.9859 - val_loss: 51.9505\n",
      "Epoch 16/25\n",
      "9/9 [==============================] - 0s 49ms/step - loss: 51.5382 - val_loss: 45.6172\n",
      "Epoch 17/25\n",
      "9/9 [==============================] - 0s 44ms/step - loss: 48.9220 - val_loss: 43.8572\n",
      "Epoch 18/25\n",
      "9/9 [==============================] - 0s 27ms/step - loss: 45.0411 - val_loss: 44.0526\n",
      "Epoch 19/25\n",
      "9/9 [==============================] - 0s 22ms/step - loss: 36.7308 - val_loss: 42.1273\n",
      "Epoch 20/25\n",
      "9/9 [==============================] - 1s 57ms/step - loss: 33.9622 - val_loss: 33.1921\n",
      "Epoch 21/25\n",
      "9/9 [==============================] - 0s 38ms/step - loss: 34.1772 - val_loss: 35.9260\n",
      "Epoch 22/25\n",
      "9/9 [==============================] - 0s 29ms/step - loss: 32.4694 - val_loss: 36.7009\n",
      "Epoch 23/25\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 33.0028 - val_loss: 38.3556\n",
      "Epoch 24/25\n",
      "9/9 [==============================] - 0s 24ms/step - loss: 30.8569 - val_loss: 34.4106\n",
      "Epoch 25/25\n",
      "9/9 [==============================] - 0s 23ms/step - loss: 29.3519 - val_loss: 33.4208\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9fc558a510>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='mae', optimizer=tf.keras.optimizers.Adam(1E-3))\n",
    "\n",
    "# Fit the model. The first epoch is slower, since it needs to cache\n",
    "# the preprocessed molecule inputs\n",
    "model.fit(train_dataset, validation_data=valid_dataset, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, we create a test dataset that doesn't assume we know the values for the YSI\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: (preprocessor(smiles, train=False)\n",
    "             for smiles in test),\n",
    "    output_signature=preprocessor.output_signature)\\\n",
    "    .padded_batch(batch_size=64)\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43.1751065296936"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here are the predictions on the test set\n",
    "test_predictions = model.predict(test_dataset)\n",
    "test_db_values = ysi.set_index('SMILES').reindex(test).YSI.values\n",
    "\n",
    "MAE = np.abs(test_db_values - test_predictions.flatten()).mean()\n",
    "MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.23847106878615"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RMSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "RMSE = mean_squared_error(test_db_values, test_predictions.flatten(), squared=False)\n",
    "RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38409635473237114"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# “reduce values” = RMSE/std dev of target data\n",
    "reduce_values = RMSE / (ysi['YSI'].std())\n",
    "reduce_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2776028795278609"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MAE/MAD\n",
    "MAE / (ysi['YSI'].mad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
